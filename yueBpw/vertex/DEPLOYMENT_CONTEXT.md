# YuE Vertex AI Deployment Context
*Generated: 2025-01-02 23:52 UTC*
*Build ID: pytorch2.6.0-cuda12.4-20250702-235238*
*Updated: 2025-01-03 01:30 UTC - Added Model Download Fix*

## ğŸ¯ **CURRENT STATUS** âš ï¸ DEPLOYED BUT NEEDS MODEL FIX

### âœ… **SUCCESSFULLY DEPLOYED:**
1. **Docker Image Built & Pushed** ğŸ‹
   - Image: `us-central1-docker.pkg.dev/music-generation-prototype/yue-models/yue-flask-server:pytorch2.6.0-cuda12.4-20250702-235238`
   - Also tagged as: `latest`
   - Size: ~3.5GB (optimized with .dockerignore)
   - Base Image: `pytorch/pytorch:2.6.0-cuda12.4-cudnn9-devel`

2. **Vertex AI Model Registry** ğŸ“¦
   - Model Name: `yue-flask-model`
   - Model ID: `7146952024381194240`
   - Version Alias: `pytorch-2-6-0`
   - Health Route: `/health`
   - Predict Route: `/predict`
   - Port: `8080`

3. **Vertex AI Endpoint DEPLOYED** ğŸ¯
   - Endpoint Name: `yue-flask-endpoint`
   - Endpoint ID: `5027878657331298304`
   - Region: `us-central1`
   - GPU: **NVIDIA A100-SXM4-40GB** âœ…
   - Status: **DEPLOYED WITH GPU!** ğŸš€

### âŒ **CRITICAL ISSUE IDENTIFIED:**
```
âŒ Stage 1 model not found at: /app/YuE-exllamav2/src/yue/models/YuE-s1-7B-anneal-en-cot
ğŸ“ Contents of /app/YuE-exllamav2/src/yue/models: Directory does not exist
```

**Root Cause**: Our `.dockerignore` excluded model weights to reduce build context. Container runs but missing actual model files.

### ğŸ”§ **SOLUTION IMPLEMENTED:**
- âœ… **Lazy model loading** on first request (not at startup)
- âœ… **Proper symlink structure** following entrypoint.py pattern
- âœ… **Thread-safe downloads** with concurrent request handling
- âœ… **Google Cloud SDK** included for gsutil downloads
- âœ… **Fast container startup** (health checks pass immediately)
- âœ… **Automatic symlink creation** from `/app/YuE-exllamav2/src/yue/models/` â†’ `/workspace/model/`

---

## ğŸš¨ **IMPROVED SOLUTION: LAZY LOADING** âœ…

### ğŸ¯ **NEW APPROACH: Download Models on First Request**
Instead of downloading models at startup, we now:
- âœ… **Fast container startup** (health checks pass immediately)
- âœ… **Lazy model download** on first prediction request  
- âœ… **Thread-safe** concurrent request handling
- âœ… **Better user experience** (no startup timeouts)

### **Step 1: Upload Models to GCS** (Required First)
```bash
# Create bucket for model weights
gsutil mb gs://yue-model-weights

# Upload Stage 1 model (you need the actual model files)
gsutil -m cp -r /path/to/YuE-s1-7B-anneal-en-cot gs://yue-model-weights/

# Upload Stage 2 model  
gsutil -m cp -r /path/to/YuE-s2-1B-general gs://yue-model-weights/
```

### **Step 2: Quick Rebuild with Lazy Loading**
```bash
cd yueBpw/vertex
./rebuild_lazy_loading.sh
```

This will:
- ğŸ—ï¸ Rebuild container with lazy loading
- ğŸ“¤ Push to Artifact Registry  
- ğŸ“¦ Upload new model version
- ğŸ”„ Update existing endpoint (keeps A100 GPU!)
- âœ… Deploy with lazy loading functionality

---

## ğŸ¯ **MANUAL GPU DEPLOYMENT GUIDE**

### âœ… **DEPLOYMENT COMPLETED!**
- **GPU Type**: NVIDIA A100-SXM4-40GB (Premium GPU!)
- **PyTorch**: 2.6.0+cu124 âœ…
- **CUDA**: Available âœ…  
- **Issue**: Missing model files only

### Container Logs from Successful Deployment:
```
âœ… PyTorch loaded: 2.6.0+cu124
âœ… CUDA available: True
âœ… GPU device: NVIDIA A100-SXM4-40GB
âŒ Stage 1 model not found at: /app/YuE-exllamav2/src/yue/models/YuE-s1-7B-anneal-en-cot
```

---

## ğŸ“‹ **PROJECT CONFIGURATION**

### GCP Settings:
- **Project ID**: `music-generation-prototype`
- **Region**: `us-central1`
- **Artifact Registry**: `yue-models`
- **Service Account**: `799748678255-compute@developer.gserviceaccount.com`

### Container Configuration:
- **Server**: Gunicorn production server (not Flask dev)
- **Threads**: 8 worker threads
- **Timeout**: Unlimited (for long inference)
- **Health Check**: `/health` endpoint
- **Prediction**: `/predict` endpoint (Vertex AI format)
- **NEW**: **Model Download**: Automatic from `gs://yue-model-weights/`

### Model Paths (inside container):
- **Stage 1**: `/app/YuE-exllamav2/src/yue/models/YuE-s1-7B-anneal-en-cot`
- **Stage 2**: `/app/YuE-exllamav2/src/yue/models/YuE-s2-1B-general`
- **Output**: `/app/YuE-exllamav2/output/{request_id}/`
- **GCS Source**: `gs://yue-model-weights/YuE-s1-7B-anneal-en-cot` and `gs://yue-model-weights/YuE-s2-1B-general`

---

## ğŸ”§ **UPDATED DOCKERFILE CHANGES**

### New Dependencies Added:
```dockerfile
# Google Cloud SDK for gsutil
RUN apt-get install -y gnupg lsb-release && \
    echo "deb [signed-by=/usr/share/keyrings/cloud.google.gpg] https://packages.cloud.google.com/apt cloud-sdk main" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list && \
    curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key --keyring /usr/share/keyrings/cloud.google.gpg add - && \
    apt-get update && apt-get install -y google-cloud-cli
```

### New Server.py Functions:
- `download_models_from_gcs()`: Downloads models and creates proper symlinks
- `ensure_models_downloaded_lazy()`: Thread-safe lazy loading on first request
- `validate_models()`: Checks symlink structure and sets MODELS_LOADED flag
- Uses `gsutil -m cp -r` for efficient multi-threaded downloads

### Symlink Structure (Following entrypoint.py Pattern):
```
/workspace/model/                          # Model storage directory
â”œâ”€â”€ YuE-s1-7B-anneal-en-cot/              # Downloaded Stage 1 model
â””â”€â”€ YuE-s2-1B-general/                    # Downloaded Stage 2 model

/app/YuE-exllamav2/src/yue/models/        # YuE expected paths (symlinks)
â”œâ”€â”€ YuE-s1-7B-anneal-en-cot -> /workspace/model/YuE-s1-7B-anneal-en-cot/
â””â”€â”€ YuE-s2-1B-general -> /workspace/model/YuE-s2-1B-general/
```

### Testing Symlinks:
```bash
# Run inside container to verify symlink structure
python3 test_symlinks.py
```

---

## ğŸ§ª **TESTING AFTER MODEL FIX**

### 1. Health Check (Should work after model fix):
```bash
curl -X GET https://ENDPOINT_URL/health
```

### 2. Sample Request:
```bash
curl -X POST https://ENDPOINT_URL/predict \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $(gcloud auth print-access-token)" \
  -d '{
    "instances": [{
      "data": {
        "user_id": "test_user_123",
        "song_name": "Test Song", 
        "lyrics": "This is a test song\nWith simple lyrics",
        "genre": "pop"
      }
    }]
  }'
```

---

## ğŸ—ï¸ **ARCHITECTURAL DETAILS**

### Dependencies:
- **PyTorch**: 2.6.0 + CUDA 12.4 + cuDNN 9 âœ…
- **ExllamaV2**: Prebuilt wheels for PyTorch 2.6.0 âœ…
- **Flash Attention**: Optimized for CUDA 12.4 âœ…
- **Flask/Gunicorn**: Production web server âœ…
- **GCS**: File upload (boto3 S3-compatible API) âœ…
- **NEW**: **Google Cloud SDK**: Model downloads via gsutil âœ…

### Request Flow:
1. **Container Startup** â†’ Download models from GCS if missing
2. **Vertex AI** â†’ `/predict` endpoint
3. **Queue System** â†’ Sequential processing (prevents GPU memory issues)
4. **Subprocess Execution** â†’ `python src/yue/infer.py` with real-time logs
5. **File Upload** â†’ GCS bucket `yue-generated-songs`
6. **Response** â†’ Request ID + status tracking

---

## ğŸš¨ **DEPLOYMENT STATUS SUMMARY**

### âœ… **WORKING:**
- GPU deployment with A100
- PyTorch 2.6.0 + CUDA 12.4
- Container startup and networking
- All dependencies loaded correctly

### âŒ **NEEDS FIX:**
- Model files missing from container
- Need to upload models to `gs://yue-model-weights/`
- Need to rebuild container with model download capability

### ğŸ¯ **NEXT ACTION:**
1. Upload YuE models to GCS bucket `gs://yue-model-weights/`
2. Rebuild container with model download fixes
3. Redeploy to existing endpoint (keeps A100 GPU)
4. Test functionality

---

*ğŸµ Container successfully deployed with A100 GPU - just needs model files! ğŸš€* 